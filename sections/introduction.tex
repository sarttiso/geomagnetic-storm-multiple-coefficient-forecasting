Mankind has experienced a number of blackouts caused by geomagnetically induced currents (GICs), which can result in millions of dollars of damages and leave millions without electricity \citep{Bolduc2002, Love2018}. The possibility of such disruptions has motivated the goal of forecasting GICs. All GICs in turn result from geomagnetic storms, which generate the variation in Earth's external field that induces GICs. The problem of forecasting GICs then amounts to forecasting geomagnetic storms. These storms result from the propagation of solar activity via the solar wind and its coupling to Earth's magnetosphere. Given abundant observational data of the solar wind and disk as well as of Earth's magnetic field, the application of data-hungry deep learning algorithms is suitable for the forecasting problem.  


%%
%% OVERVIEW OF SOLAR WIND
%%
\subsection{Geomagnetic storms}\label{sec:SW}

Geomagnetic storms have traditionally been quantified by indices such as the disturbance storm time (Dst in nT) or Kp (unitless) indices (e.g. \cite{Bartels1939}), both of which register deviations from the quiet time horizontal component of Earth's magnetic field. The basic mechanism of geomagnetic storm formation is the strengthening of Earth's ring current in response to changing solar wind conditions, and this strengthened current system generates a magnetic field that counters Earth's dipole, weakening it relative to quiet conditions \citep{Daglis1999}. The solar wind parameters most important for strengthening the ring current are its southward component of the inter-planetary magnetic field (IMF), velocity, and plasma density, which all positively impact storm amplitude \citep{Wolf1997,Gonzalez1999,Daglis1999}. All solar wind activity that generates significant, rapid fluctuation in Earth's external magnetic field poses a threat to ground-based conducting systems, such as power and communication lines, during geomagnetic storms.


%%
%% DEEP LEARNING
%%
% \subsection{Deep learning}
% Deep learning refers to the application of Neural Networks (NN) to classification or regression problems. Neural networks, in turn, are fundamentally composed of interconnected ``neurons'', where each neuron represents a ridge function,
% \begin{equation}
% f(\mathbf{x}) = \gamma(\mathbf{w}\cdot\mathbf{x} + b)
% \end{equation}
% where input data $\mathbf{x}$ first go through an affine transformation $\mathbf{w}\cdot\mathbf{x} + b$ followed by a nonlinear transformation $\gamma(.)$. For non-polynomial nonlinear functions $\gamma()$, the span of the ridge functions is dense in the set of continuous functions, meaning that a linear combination of sufficiently many ridge functions can approximate any continuous function to arbitrary precision \citep{Leshno1993,Pinkus1999}. In general, the number of required functions is unknown, so rather than adding more neurons, researchers have found success by chaining ridge functions into layers, forming ``deep'' networks. Each subsequent layer contains neurons that take as input the outputs of the previous layer, in the simplest case forming the classical feed-forward multilayered perceptron. The optimal constants $\mathbf{w}$ and $b$ are found for each "neuron" via gradient descent minimization of a chosen cost function. Given the typical non-convexity of the problem, globally optimal solutions are not guaranteed.

% WHY DEEP LEARNING
\subsection{Why deep learning?}
Given the complexity of the underlying physics, which involves the magnetohydrodynamics (MHD) and plasma physics of propagating solar activity through the solar wind and its subsequent interaction with Earth's magnetosphere, a fully physical forward model of the system would be both computationally expensive and poorly constrained. At the same time, given that we are aware of the important physical quantities responsible for geomagnetic storms, such a physical model is overkill for the problem of forecasting the low-order response of Earth's magnetic field to solar activity.

For this reason, the first approach to geomagnetic storm modeling took the form of simple empirical models that related the time rate of change of Dst to solar wind parameters. The pioneering work was a three-term deterministic model developed by \cite{Burton1975}, but its simplicity, while elegant, often generates inaccurate forecasts. Subsequent modeling has attempted to improve accuracy by adding more degrees of freedom. For example, while obtaining more predictive power, \cite{Temerin2006} added almost a dozen more terms with significantly more complex functional forms, sacrificing the simplicity of the initial model. Neural networks (NNs), which form the backbone of deep learning, are the logical conclusion to the exercise of adding more and more heuristic functional forms, since the task of a NN is to learn the relevant functions rather than have them prescribed\added{: even a single layer neural network with sufficient ``neurons'' is capable of approximating any continuous function to arbitrary precision  \citep{Leshno1993,Pinkus1999}.} \replaced{However, given that this sufficient number of neurons in a single layer network is typically unknown and potentially intractable, workers have found success by instead adding layers of neurons rather than neurons themselves. This composition of layers, in which neurons in a given layer operate on the outputs of neurons from the preceding one, is coined ``deep learning'', and has met with unprecedented success in classification and regression problems. While still poorly understood beyond a heuristic sense, some workers hypothesize that deep neural networks are successful because many learning problems are outcomes of hierarchical and compositional processes, which deep networks can efficiently reproduce \citep{Lin2017, Brahma2016}. Furthermore, \cite{Lin2017} demonstrate how the properties of symmetry, locality, and polynomial log-probability in many natural processes are efficiently learned by even relatively shallow (i.e., consisting of a handful of hidden layers) neural networks.}{While NNs provide a flexible framework for learning the appropriate functions that dictate the system dynamics, it is more diffcult to interpret the complex interactions of neurons and the abundance of learnable parameters (weights and biases). The latter also means that NNs require abundant data to be effectively trained. Fortunately, decades of observations of the solar wind and solar disk provide a suitable dataset necessary for deep learning.}

%%
%% PRIOR WORK
%%
\subsection{Prior applications of deep learning to geomagnetic storm forecasting}\label{sec:prior_work}
Previous work with NNs has focused almost entirely on prediction of Dst or other indices of geomagnetic activity, such as the Kp and the auroral electrojet (AE) indices. Supplemental Table~S1 provides a succinct review of the application of NNs to the forecasting of Dst \citep{Andriyas2015, Bala2012, Gleisner1996, Jankovivcova2002, Kugblenu1999, Lazzus2017, Munsami2000, Pallocchia2006, Revallo2014, Sharifie2006, Stepanova2005, Stepanova2000, Wei2007, Wu1996, Wu1997a}. These studies have applied a variety of architectures and data sources, but in generating forecasts for Dst, most have used the basic solar wind parameter measurements as well as prior values of Dst. All previous studies applying NNs to Dst forecasting to our knowledge have utilized observations made at the Earth-Sun L1 point or closer\added{, with the exception of \cite{Chakraborty2020}, who include solar x-ray fluxes}. Furthermore, \added{almost} all studies to date using NNs to forecast Dst (or any other geomagnetic storm index) have been deterministic, generating predictions without any measure of uncertainty.\deleted{Only} \cite{Gruet2018} \deleted{attempt do} assess uncertainty in their forecasts \replaced{via a}{but they use a} Gaussian process model \replaced{with fixed kernel parameters}{to develop uncertainty estimates}, and \replaced{this process takes as input their deterministic NN forecasts}{their NN output is deterministic}. \added{\cite{Chakraborty2020} on the other hand use a deep long short term memory (LSTM) network to learn how to dynamically update the kernel parameters for a Gaussian process representation of the Kp index, which is how they generate probabilistic forecasts. Finally, while not utilizing neural networks, \cite{Gu2019} generate probabilistic forecasts of the auroral electrojet (AE) index by considering output from an ensemble of 100 nonlinear autoregressive models trained on independently resampled subsets of their data.}

This work improves on previous advances by presenting the first application of probabilistic neural networks \replaced{that explicitly generate measures of uncertainty in their output}{to geomagnetic storm forecasting, utilizing recent developments in deep learning to generate forecasts with uncertainty}. Our networks are capable of learning how confident to be in their predictions, and in doing so improve forecast reliability. These networks take as input not just observations from the L1 point but also observations of radiative phenomena on the solar disk. Finally, instead of forecasting Dst, we focus on its external component, Est, which does not incorporate the effects of Earth's subsurface conductivity structure.